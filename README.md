# DATA3888 2025 Imaging15 Reproducible guide

## 1. Data cleaning, extracting, and Pre-processing

Data pre-processing, feature extraction, and data splitting scripts are primarily located within the `src` directory, with specific paths mentioned below. The main configuration for paths and parameters is controlled by `config.yaml` in the root directory.

We intend to put the source image in Image_Data folder as following "Image_Data/50/*cell type*/*cell type*/*the .png cell image*"

### a. Initial Dataset Preparation and Augmentation

* **Script:** `extract_random_images.py`
* **Purpose:** Takes a directory of raw images (organized by class in subdirectories) and performs a class-specific augmentations to the training set to reach target sample counts per class.
* **Typical Input:** Raw image data (e.g., from `data/raw/50/`). Path is specified via the `--src` argument.
* **Typical Output:** Augmented and split images into `train` and `test` subdirectories within an interim data folder (e.g., `data/interim/original/`). Path is specified via the `--dst` argument (defaults to `data/interim/original` as per `config.yaml`'s `paths: base_data_dir`).
* **Key Libraries:** `albumentations`, `opencv-python` (cv2), `tqdm`, `pathlib`.

### b. Stratified K-Fold Split Generation

* **Script:** `src/common/make_splits.py`
* **Purpose:** Takes the 'train' subdirectory created by `extract_random_images.py` (or any similarly structured directory) and generates stratified k-fold cross-validation split files (CSVs). It groups augmented images with their original counterparts for consistent splitting.
* **Typical Input:** The training image data directory (e.g., `data/interim/original/`). Path is specified via the `--data_root` argument.
* **Typical Output:** CSV files named `fold_1.csv`, `fold_2.csv`, etc., containing relative image paths and labels. These are saved to the directory specified by `--output_dir` (e.g., `data/splits/` as per `config.yaml`'s `paths: splits_dir`).
* **Key Libraries:** `scikit-learn`, `numpy`, `pandas` (implicitly for CSV handling, though the `csv` module is used directly).

### c. HOG Feature Extraction (for Random Forest and other classical ML models)

* **Script:** `src/ml/feature_extractor/hog.py`
* **Purpose:** Extracts Histogram of Oriented Gradients (HOG) features from images. It processes images listed in the fold CSVs (generated by `make_splits.py`), converts them to specified colorspaces (e.g., 'grayscale', 'ycbcr', 'cielab', 'hed' as defined in `config.yaml`), and then extracts HOG features.
* **Typical Input:**
  * Original RGB image data root (e.g., `data/interim/original/`), specified by `--image_data_root`.
  * Directory containing split CSV files (e.g., `data/splits/`), specified by `--splits_dir`.
  * A specific fold ID stem (e.g., `fold_1` or a sampled version like `fold_1_samplefrac_0.200`), specified by `--fold_id`.
  * Target colorspace, specified by `--target_colorspace`.
* **Typical Output:**
  * Pickled HOG feature arrays (e.g., `fold_1_hog_features.pkl`).
  * Pickled label lists (e.g., `fold_1_hog_labels.pkl`).
  * Pickled image path lists (e.g., `fold_1_hog_paths.pkl`).
  * These are saved in a structured directory like `data/features_ml/hog_<colorspace>/` (base path from `config.yaml`'s `paths: base_feature_dir`).
* **Key Libraries:** `scikit-image`, `numpy`, `joblib`, `Pillow`, `pandas`, `tqdm`.

## 2. Model training

Model training is orchestrated by `run_all_folds.py`, which iterates through cross-validation folds, colorspaces, and model types defined in `config.yaml`. It calls specific training scripts for different model architectures. Due to the large file size of models, the "Data Models" folder only include the analysis file, the actual trained model files (.keras) have been uploaded to this google drive: https://drive.google.com/drive/folders/1SWV4fgqqE_NHKe8cSk0VtAYqoQBZgcak

### a. Main Orchestration Script

* **Script:** `run_all_folds.py`
* **Purpose:**
  * Loads the main `config.yaml`.
  * Manages k-fold cross-validation loops.
  * If Random Forest (RF) or other specified ML models are in `experiments: model_types`, it first calls `src/ml/feature_extractor/hog.py` for all folds and necessary colorspaces to generate HOG features. It handles potential sampling of input CSVs for HOG extraction based on `test_run` settings or `hyperparameters: rf: full_mode_sample_fraction`.
  * For Deep Learning (DL) models (ResNet, MobileNetV2, EfficientNetB0):
    * Generates a temporary run-specific YAML configuration for each training job.
    * Calls the respective training script (e.g., `src/dl/efficientnetb0/train.py`).
  * For ML models (e.g., Random Forest):
    * Calls the respective training script (e.g., `src/ml/rf/train.py`) with appropriate HOG feature paths.
* **Key Command-line Arguments:**
  * `--mode`: `full` (default) or `test`. The `test` mode uses override parameters from `config.yaml` (e.g., fewer epochs, smaller sample fraction).
  * `--run_folds`: Allows specifying particular validation fold numbers to run (e.g., `1 3 5`). If not provided, all folds are run.
* **Outputs:** Organizes all outputs from individual training runs into directories like:
  `outputs/<model_type>/<experiment_name_timestamp_mode_fold>/fold_<fold_num>/`
  (e.g., `outputs/resnet/original_resnet_exp_240530_103000_fullrun_val1/fold_1/`).
  The `experiment_name` includes colorspace, model type, timestamp, run mode, and validation fold.
* **Key Libraries:** `PyYAML`, `pandas`, `scikit-learn`, `tqdm`, `subprocess`.

### b. Deep Learning Model Training (Example: EfficientNetB0)

* **Scripts:**
  * Architecture: `src/dl/efficientnetb0/model.py` (defines the Keras model).
  * Training: `src/dl/efficientnetb0/train.py` (handles data loading, training loop, evaluation).
  * (Similar structures exist for `resnet` and `mobilenetv2` in their respective `src/dl/` subdirectories).
* **Purpose:** Trains a specific DL model (e.g., EfficientNetB0) for a given fold and colorspace.
* **Input:**
  * A temporary run-specific YAML configuration file (generated by `run_all_folds.py`) passed via the `--config` argument. This file specifies:
    * Hyperparameters for the model (epochs, batch size, learning rate, etc.).
    * Paths to original image data (`data/interim/original/`) and split CSVs (`data/splits/`).
    * The current validation fold number and total folds.
    * Target colorspace for image preprocessing.
    * Optional sample fraction for test runs.
* **Output (within the experiment's `fold_<fold_num>` subdirectory, e.g., `outputs/efficientnetb0/.../fold_1/`):**
  * `model_best.keras`: Saved Keras model with the best validation accuracy.
  * `model_final.keras`: Saved Keras model at the end of training.
  * **`report.txt`**: Classification report (precision, recall, F1-score, accuracy) on the validation set.
  * `report_dict.json`: Classification report as a JSON object.
  * `confusion_matrix.csv`: Confusion matrix on the validation set.
  * **`training_time.txt`**: Text file containing the duration of the training process.
  * `training_performance.png`: Plot of training/validation accuracy and loss over epochs.
  * `y_true.npy`, `y_pred.npy`, `y_pred_probs.npy`: True labels, predicted labels, and prediction probabilities for the validation set.
* **Key Libraries:** `PyYAML`, `numpy`, `pandas`, `tensorflow` (Keras), `scikit-learn` (for metrics), `matplotlib` (for plots), `scikit-image` (for on-the-fly colorspace conversion).

### c. Classical Machine Learning Model Training (Example: Random Forest)

* **Script:** `src/ml/rf/train.py`
* **Purpose:** Trains a Random Forest classifier using pre-extracted HOG features for a given fold and colorspace.
* **Input (passed as command-line arguments by `run_all_folds.py`):**
  * `--output_dir`: Directory to save model and results (e.g., `outputs/rf/.../fold_1/`).
  * `--base_feature_dir`: Root directory of HOG features (e.g., `data/features_ml/`).
  * `--colorspace`: The colorspace of HOG features to use.
  * `--val_fold_hog_stem`: The stem name of the HOG feature file to be used for validation (e.g., `fold_1` or `fold_1_samplefrac_0.200`).
  * `--all_hog_stems_json`: A JSON string list of all HOG stems relevant for the k-fold setup (used to identify training folds).
  * Hyperparameters for Random Forest (e.g., `n_estimators`, `max_depth`).
* **Output (within the experiment's `fold_<fold_num>` subdirectory, e.g., `outputs/rf/.../fold_1/`):**
  * `model.pkl`: Saved trained Random Forest model (using joblib).
  * **`report.txt`**: Classification report on the validation set.
  * `report_dict.json`: Classification report as a JSON object.
  * `confusion_matrix.csv`: Confusion matrix on the validation set.
  * `confusion_matrix_labels.json`: JSON list of class labels for the confusion matrix.
  * **`training_time.txt`**: Text file containing the duration of the training process.
  * `y_true_val.npy`, `y_pred_val.npy`: True labels and predicted labels for the validation set.
* **Key Libraries:** `numpy`, `joblib`, `scikit-learn` (ensemble, metrics, model_selection), `json`.

### Required Python Libraries:

* `PyYAML`
* `pandas`
* `numpy`
* `scikit-learn`
* `scikit-image`
* `tensorflow`
* `opencv-python` 
* `albumentations`
* `matplotlib`
* `joblib`
* `Pillow` 
* `tqdm`

## 3. Final Report's table and figures

The final report's R code (It's also separated to "graph.Rmd" file) will extract the analysis data generated during model training, specifically in the "report.txt" and "training_time.txt" file, located inside "DATA Models/*model_type*/*colourspace*/fold *" folder to create a table showing the average performance metrics (accuracy, precision, time) across all folds. The code will also create a "avg_model_performance.csv" file that can be used to generate the side-by-side plot in R Shiny application by putting the csv file inside "Imaging_Shiny/training_data"

The code that count the cell files to output the barplot were also separated into "barplot_figure.Rmd" for convenient

## 4. R Shiny deployment (This was done through Window Subsystem for Linux 2 Ubuntu)

### Required packages

The whole R Shiny app is located inside "Imaging_Shiny", using R version 4.4.1

The deployment process was tested through Window Subsystem for Linux 2 Ubuntu, the installation for Window version using RStudio should remain the same albeit without having to install extra packages in Bash terminal

Before launching R, go inside the app folder:

* `cd Imaging_Shiny` to go inside the app folder
* `R` to launch R

Required packages are listed inside "Imaging_Shiny/global.R"

### Required R Packages:

* `shiny`
* `bslib`
* `shinydashboard`
* `shinydashboardPlus`
* `DT`
* `ggplot2`
* `tidyr` 
* `dplyr`
* `reticulate` - further step needed
* `keras3` - further step needed
* `EBImage` - special installation

Some further step needed for some library:

Install tensorflow through keras3, need python environment

* In Bash terminal: `sudo apt-get install python3-venv python3-pip python3-dev`
* In R terminal: `keras3::install_keras(backend = "tensorflow")`

Install EBImage through Biocmanager

* In Bash terminal: `sudo apt-get install fftw3 fftw3-dev pkg-config`
* In R terminal:
* `install.packages("BiocManager")`
* `BiocManager::install("EBImage")`

Install required python package for reticulate

* `py_install("scikit-image")`
* `py_install("numpy==1.26.4")`

### Local deployment

* `library(shiny)`
* `runApp()`

### Online deployment

The application can be deployed to R Shiny through shinyapps.io by using the "rsconnect" package, and following the guide on this shinyapps.io site: https://docs.posit.co/shinyapps.io/guide/getting_started/

Basically, after connecting your account with rsconnect, run `deployApp()` to deploy it online, the py_require() code in server.r already instruct the online environment to install python environment.

Due to the online nature of python environment, first time rebooting the instance of the app will take 3-5 minutes to install everything, and first time clicking "Classify" on "Predict" tab will take 2-3 minutes to call the prediction.py file
